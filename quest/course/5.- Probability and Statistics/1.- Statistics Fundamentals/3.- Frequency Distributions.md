# 3.- Frequency Distributions

* Steps:

![Steps](https://s3.amazonaws.com/dq-content/285/s1m3_workflow.svg)

* Using `Series.value_counts()` method to generate a frequency distribution table:

```python
>> wnba['Pos'].value_counts()
G      60
F      33
C      25
G/F    13
F/C    12
Name: Pos, dtype: int64
```

* Using `Series.sort_index()` method with `Series.value_counts()` to sort in order:

```python
>> wnba['Height'].value_counts().sort_index()
165     1
168     2
170     6
173    11
175    16
178     8
180     7
183    11
185    15
188    20
191    11
193    18
196     9
198     5
201     2
206     1
Name: Height, dtype: int64
```

* Sorting Tables for Ordinal Variables:

```python
def make_pts_ordinal(row):
    if row['PTS'] <= 20:
        return 'very few points'
    if (20 < row['PTS'] <=  80):
        return 'few points'
    if (80 < row['PTS'] <=  150):
        return 'many, but below average'
    if (150 < row['PTS'] <= 300):
        return 'average number of points'
    if (300 < row['PTS'] <=  450):
        return 'more than average'
    else:
        return 'much more than average'

wnba['PTS_ordinal_scale'] = wnba.apply(make_pts_ordinal, axis = 1)

# Type your answer below

pts_ordinal_desc = wnba['PTS_ordinal_scale'].value_counts().iloc[[4,3,0,2,1,5]]
```

* Proportions and Percentages:

![P%](https://s3.amazonaws.com/dq-content/285/s1m3_percentages.svg)

```python
proportion_25 = wnba["Age"].value_counts(normalize = True).sort_index()[25]
percentage_30 = wnba["Age"].value_counts(normalize = True).sort_index()[30]*100
percentage_over_30 = wnba["Age"].value_counts(normalize = True).sort_index().loc[30:].sum() * 100
percentage_below_23 = wnba["Age"].value_counts(normalize = True).sort_index().loc[:23].sum() * 100
```

* Percentile and Percentile Ranks, using `scipy.stats` and `percentileofscore(a = , score = , kind = )` function:

![Percentile1](https://s3.amazonaws.com/dq-content/285/s1m3_percentiles_v2.svg)

```python
>> from scipy.stats import percentileofscore
>> percentileofscore(a = wnba['Age'], score = 23, kind = 'weak')
18.88111888111888
```

![Percentile2](https://s3.amazonaws.com/dq-content/285/s1m3_difference.svg)

```python
>> 100 - percentileofscore(wnba['Age'], 29, kind = 'weak')
26.573426573426573
```

* Finding Percentiles with pandas:

![Percentile](https://s3.amazonaws.com/dq-content/285/s1m3_quantiles_v2.svg)

```python
>> wnba['Age'].describe()
count    143.000000
mean      27.076923
std        3.679170
min       21.000000
25%       24.000000
50%       27.000000
75%       30.000000
max       36.000000
Name: Age, dtype: float64

>>wnba['Age'].describe().iloc[3:]
min    21.0
25%    24.0
50%    27.0
75%    30.0
max    36.0
Name: Age, dtype: float64

>> wnba['Age'].describe(percentiles = [.1, .15, .33, .5, .592, .85, .9]).iloc[3:]
min      21.0
10%      23.0
15%      23.0
33%      25.0
50%      27.0
59.2%    28.0
85%      31.0
90%      32.0
max      36.0
Name: Age, dtype: float64
```

```python
percentiles = wnba["Age"].describe(percentiles = [.5,.75,.95])

age_upper_quartile = percentiles["75%"]
age_middle_quartile = percentiles["50%"]
age_95th_percentile = percentiles["95%"]
```

* Grouped Frequency Distribution Tables:

![Frequency1](https://s3.amazonaws.com/dq-content/285/s1m3_ten_intervals.svg)

```python
>> wnba['Weight'].value_counts(bins = 10).sort_index()
(54.941, 60.8]     5
(60.8, 66.6]      21
(66.6, 72.4]      10
(72.4, 78.2]      33
(78.2, 84.0]      31
(84.0, 89.8]      24
(89.8, 95.6]      10
(95.6, 101.4]      3
(101.4, 107.2]     2
(107.2, 113.0]     3
Name: Weight, dtype: int64
```

```python
grouped_freq_table = wnba["PTS"].value_counts(normalize = True, 
                     bins = 10).sort_index(ascending = False) * 100
```

* Information loss, use 10 class intervals:

![Class1](https://s3.amazonaws.com/dq-content/285/s1m3_tradeoff.svg)

* Readability for Grouped Frequency Tables:

```python
wnba['PTS'].value_counts(bins = 5).sort_index()
(1.417, 118.4]    54
(118.4, 234.8]    37
(234.8, 351.2]    25
(351.2, 467.6]    18
(467.6, 584.0]     9
Name: PTS, dtype: int64

>> intervals = pd.interval_range(start = 0, end = 600, freq = 100)
>> intervals
IntervalIndex([(0, 100], (100, 200], (200, 300], (300, 400], (400, 500], (500, 600]]
              closed='right',
              dtype='interval[int64]')

>> gr_freq_table = pd.Series([0,0,0,0,0,0], index = intervals)
>> gr_freq_table
(0, 100]      0
(100, 200]    0
(200, 300]    0
(300, 400]    0
(400, 500]    0
(500, 600]    0
dtype: int64

>> for value in wnba['PTS']:
       for interval in intervals:
           if value in interval:
               gr_freq_table.loc[interval] += 1
               break
>> gr_freq_table
(0, 100]      49
(100, 200]    28
(200, 300]    32
(300, 400]    17
(400, 500]    10
(500, 600]     7
dtype: int64

>> gr_freq_table.sum()
143
```

* Workflow:

![Workflow3](https://s3.amazonaws.com/dq-content/285/s1m3_3rd_step_done.svg)

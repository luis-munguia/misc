# 4.- Web Scraping

* Web pages use **HyperText Markup Language** `HTML`:

![HTML1](https://dq-content.s3.amazonaws.com/6ne0anS.png)

```html
<html>
  <head>
    <title>A simple example page</title>
  <head>
  <body>
    <p>Here is some simple content for this page.</p>
    <p><b>Hello, this is a bold paragraph.</b></p>  
  <body>
</html>
```

`b` - tag that bolds content inside it.

`p` - tag that creates a new single paragraph.

`head` - tag with information useful to Web browser.

`body` - tag with the bulk of content.

`title` - tag with the information to display at the top of the tab.

* Using `requests` and `beautifulsoup` libraries:

```python
# Using requests library.
response = requests.get("http://dataquestio.github.io/web-scraping-pages/simple.html")
content = response.content
```

```python
from bs4 import BeautifulSoup

# Initialize the parser, and pass in the content we grabbed earlier.
parser = BeautifulSoup(content, 'html.parser')

# Get the body tag from the document.
# Since we passed in the top level of the document to the parser, we need to pick a branch off of the root.
# With BeautifulSoup, we can access branches by using tag types as attributes.
body = parser.body

# Get the p tag from the body.
p = body.p

# Print the text inside the p tag.
# Text is a property that gets the inside text of a tag.
print(p.text)

# I can nest all code in a single sentence.
title_text = parser.head.title.text

print(title_text)
```

* Using `.find_all()` method to parse better:

```python
parser = BeautifulSoup(content, 'html.parser')

# Get a list of all occurrences of the body tag in the element.
body = parser.find_all("body")

# Get the paragraph tag.
p = body[0].find_all("p")

# Get the text.
print(p[0].text)

head = parser.find_all("head")
title = head[0].find_all("title")
print(title[0].text)
```

* Using **IDs** to refert to a specific element:

![HTML2](https://dq-content.s3.amazonaws.com/WBG4aCQ.png)

```python
# Get the page content and set up a new parser.
response = requests.get("http://dataquestio.github.io/web-scraping-pages/simple_ids.html")
content = response.content
parser = BeautifulSoup(content, 'html.parser')

# Pass in the ID attribute to only get the element with that specific ID.
first_paragraph = parser.find_all("p", id="first")[0]
print(first_paragraph.text)

second_paragraph_text = parser.find_all("p", id="second")[0].text
print(second_paragraph_text)
```

* Using `class_` to parse website:

```python
# Get the website that contains classes.
response = requests.get("http://dataquestio.github.io/web-scraping-pages/simple_classes.html")
content = response.content
parser = BeautifulSoup(content, 'html.parser')

# Get the first inner paragraph.
# Find all the paragraph tags with the class inner-text.
# Then, take the first element in that list.
first_inner_paragraph = parser.find_all("p", class_="inner-text")[0]
print(first_inner_paragraph.text)

second_inner_paragraph_text = parser.find_all("p", class_="inner-text")[1].text
print(second_inner_paragraph_text)

first_outer_paragraph_text = parser.find_all("p", class_="outer-text")[0].text
print(first_outer_paragraph_text)
```

* Using **Cascading Style Sheets** or **CSS selectors** to parse:

```html
<!--This will make all of the text inside all paragraphs red.-->
p{
    color: red
 }

<!--This will make any paragraphs that have the specified class red.-->
p.inner-text{
    color: red
 }

<!--This will make any paragraphs that have the specified ID red.-->
p#first{
    color: red
 }

<!--This will make any elements that have the specified ID red.-->
#first{
    color: red
 }

<!--This will make any elements that have the specified class red.-->

.inner-text{
    color: red
 }
```

![HTML3](https://dq-content.s3.amazonaws.com/uOaCMeY.png)

```python
# Get the website that contains classes and IDs.
response = requests.get("http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html")
content = response.content
parser = BeautifulSoup(content, 'html.parser')

# Select all of the elements that have the first-item class.
first_items = parser.select(".first-item")

# Print the text of the first paragraph (the first element with the first-item class).
print(first_items[0].text)

first_outer_text = parser.select(".outer-text")[0].text
second_text = parser.select("#second")[0].text
```

* **CSS selectors** can be nested ans used to extract data from webiste with complex layouts:

![HTML4](https://dq-content.s3.amazonaws.com/H34hK8I.png)

```python
# Get the Superbowl box score data.
response = requests.get("http://dataquestio.github.io/web-scraping-pages/2014_super_bowl.html")
content = response.content
parser = BeautifulSoup(content, 'html.parser')

# Find the number of turnovers the Seahawks committed.
turnovers = parser.select("#turnovers")[0]
seahawks_turnovers = turnovers.select("td")[1]
seahawks_turnovers_count = seahawks_turnovers.text
print(seahawks_turnovers_count)

# Find the Total Plays for the NEP.
play_counts = parser.select("#total-plays")[0]
patriot_plays = play_counts.select("td")[2]
patriots_total_plays_count = patriot_plays.text

# Find the Total Yards for SEA.
yard_counts = parser.select("#total-yards")[0]
seahawks = yard_counts.select("td")[1]
seahawks_total_yards_count = seahawks.text
```

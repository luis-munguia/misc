# Multivariate K-Nearest Neighbors

* Recap code:

```python
import pandas as pd
import numpy as np
np.random.seed(1)

dc_listings = pd.read_csv('dc_airbnb.csv')
dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]
stripped_commas = dc_listings['price'].str.replace(',', '')
stripped_dollars = stripped_commas.str.replace('$', '')
dc_listings['price'] = stripped_dollars.astype('float')

dc_listings.info()
```

* Removing features:

```python
drop_columns = ['room_type', 'city', 'state', 'latitude', 'longitude', 'zipcode', 'host_response_rate',
                'host_acceptance_rate', 'host_listings_count']

dc_listings.drop(columns = drop_columns, inplace = True)
```

* Handling missing values:

```python
print(dc_listings.isnull().sum())
columns = ['cleaning_fee', 'security_deposit']
dc_listings.drop(columns = columns, inplace = True)
dc_listings.dropna(axis = 0, inplace = True)
dc_listings.info()
```

* Normalize columns:

```python
normalized_listings = (dc_listings - dc_listings.mean()) / dc_listings.std()
normalized_listings["price"] = dc_listings["price"]
print(normalized_listings.iloc[:2])
```

* Euclidean distance for multivariate case:

```python
from scipy.spatial import distance

first_listing = normalized_listings.iloc[0][['accommodates', 'bathrooms']]
fifth_listing = normalized_listings.iloc[4][['accommodates', 'bathrooms']]
first_fifth_distance = distance.euclidean(first_listing, fifth_listing)
print(first_fifth_distance)
```

* Introduction to `scikit-learn`:

  * instantiate the specific machine learning model you want to use
  * fit the model to the training data
  * use the model to make predictions
  * evaluate the accuracy of the predictions
  
  
```python
from sklearn.neighbors import KNeighborsRegressor
knn = KNeighborsRegressor()
```

* Using the defaults:
  * `n_neighbors`: the number of neighbors, is set to `5`.
  * `algorithm`: for computing nearest neighbors, is set to `auto`.
  * `p`: set to `2`, corresponding to Eucledian distance.
  
```python
knn = KNeighborsRegressor(algorithm='brute')
```

* Fitting a model and making predictions:

```python

from sklearn.neighbors import KNeighborsRegressor

train_df = normalized_listings.iloc[0:2792]
test_df = normalized_listings.iloc[2792:]
train_columns = ['accommodates', 'bathrooms']

# Instantiate ML model.
knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')

# Fit model to data.
knn.fit(train_df[train_columns], train_df['price'])

# Use model to make predictions.
predictions = knn.predict(test_df[train_columns])
```

* Calculating MSE using Scikit_Learn:

```python
from sklearn.metrics import mean_squared_error

train_columns = ['accommodates', 'bathrooms']
knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')
knn.fit(train_df[train_columns], train_df['price'])
predictions = knn.predict(test_df[train_columns])

two_features_mse = mean_squared_error(test_df["price"], predictions)
two_features_rmse = np.sqrt(two_features_mse)
```

* Using more features:

| feature(s) | MSE | RMSE |
| --- | --- | ---|
| accomodates | 18646.5 | 136.6 |
| bathrooms | 17333.4 | 131.7 |
| accommodates, bathrooms | 15660.4 | 125.1 |

```python
features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']
from sklearn.neighbors import KNeighborsRegressor
knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')

knn.fit(train_df[features], train_df["price"])
four_predictions = knn.predict(test_df[features])

four_mse = mean_squared_error(test_df["price"], four_predictions)
four_rmse = np.sqrt(four_mse)
print(four_mse, four_rmse)
```

* Using all features:

```python
all_features = list(train_df.columns)
del all_features[4]

knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')

knn.fit(train_df[all_features], train_df["price"])
all_features_predictions = knn.predict(test_df[all_features])

all_features_mse = mean_squared_error(test_df["price"], all_features_predictions)
all_features_rmse = np.sqrt(all_features_mse)
print(all_features_mse, all_features_rmse)
```

* Feature selection:

Go from:

  * Increase the number of attributes the model uses to calculate similarity when ranking the closest neighbors.
  
to:

  * Select the relevant attributes the model uses to calculate similarity when ranking the closest neighbors.
  
  

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datacamp Personal Takeaways \n",
    "## Cleaning Data With Python by Daniel Chen\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Exploring your data.\n",
    "Use pandas to review shape and current status of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dataframe methods and attributes.\n",
    "```python\n",
    "# Import libraries needed\n",
    "import pandas as pd\n",
    "\n",
    "df.head()\n",
    "df.tail()\n",
    "df.shape\n",
    "df.columns\n",
    "df.info()\n",
    "# If column name is not strange, can use dot notation.\n",
    "df.columnname.value_counts()\n",
    "# See statistic info from dataset.\n",
    "df.columnname.describe()\n",
    "\n",
    "df.columnname.plot(kind=\"hist\")\n",
    "df.boxplot(column =\"columnname1\", by= \"columnname2\")\n",
    "df.plot(kind= \"scatter\", x=\"columnname1\", y=\"columname2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Tidying data for analysis.\n",
    "Use Hadley Wickham's tidy data concept: \n",
    "1. Each variable forms a column.\n",
    "2. Each observation forms a row.\n",
    "3. Each type of observational unit forms a table.\n",
    "\n",
    "**Remember!**\n",
    "\n",
    "This is for data cleaning, not for data viz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using melt.\n",
    "```python\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(airquality, id_vars='Date', var_name=\"measurement\", value_name=\"reading\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pivot.\n",
    "```python\n",
    "# Pivot airquality_melt: airquality_pivot\n",
    "airquality_pivot = airquality_melt.pivot(index=\"Date\", columns=\"measurement\", values=\"reading\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset index after pivot.\n",
    "```python\n",
    "# Reset the index of airquality_pivot: airquality_pivot_reset\n",
    "airquality_pivot_reset = airquality_pivot.reset_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot duplicate values.\n",
    "```python\n",
    "# Pivot table the airquality_dup: airquality_pivot\n",
    "airquality_pivot = airquality_dup.pivot_table(index=\"Date\", columns=\"measurement\", values=\"reading\", aggfunc=np.mean)\n",
    "\n",
    "# Reset the index of airquality_pivot\n",
    "airquality_pivot = airquality_pivot.reset_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new columns with string slicing.\n",
    "```python\n",
    "# Create the 'gender' column\n",
    "tb_melt['gender'] = tb_melt.variable.str[0]\n",
    "\n",
    "# Create the 'age_group' column\n",
    "tb_melt['age_group'] = tb_melt.variable.str[1:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new columns with string splitting.\n",
    "```python\n",
    "# Create the 'str_split' column\n",
    "ebola_melt['str_split'] = ebola_melt[\"type_country\"].str.split(\"_\")\n",
    "\n",
    "# Create the 'type' column\n",
    "ebola_melt['type'] = ebola_melt[\"str_split\"].str.get(0)\n",
    "\n",
    "# Create the 'country' column\n",
    "ebola_melt['country'] = ebola_melt[\"str_split\"].str.get(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Combining data for analysis.\n",
    "So what if you have multiple datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using concatenation row or column wise.\n",
    "```python\n",
    "# Concatenate uber1, uber2, and uber3: row_concat\n",
    "row_concat = pd.concat([uber1,uber2,uber3])\n",
    "\n",
    "# Concatenate ebola_melt and status_country column-wise: ebola_tidy\n",
    "ebola_tidy = pd.concat([ebola_melt, status_country], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Globbing to find files in machine to concatenate.\n",
    "```python\n",
    "\"\"\"\n",
    "Wildcards: * and ?\n",
    "    Any csv file: *.csv\n",
    "    Any single character: file_?.csv\n",
    "\"\"\"\n",
    "# Import necessary modules\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Write the pattern: pattern\n",
    "pattern = '*.csv'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "csv_files = glob.glob(pattern)\n",
    "\n",
    "# Create an empty list: frames\n",
    "frames = []\n",
    "\n",
    "#  Iterate over csv_files\n",
    "for csv in csv_files:\n",
    "\n",
    "    #  Read csv into a DataFrame: df\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Append df to frames\n",
    "    frames.append(df)\n",
    "\n",
    "# Concatenate frames into a single DataFrame: uber\n",
    "uber = pd.concat(frames)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data.\n",
    "```python\n",
    "# Merge the DataFrames: o2o\n",
    "o2o = pd.merge(left=site, right=visited, left_on=\"name\", right_on=\"site\")\n",
    "\n",
    "# Merge the DataFrames: m2o\n",
    "m2o = pd.merge(left=site, right=visited, left_on=\"name\", right_on=\"site\")\n",
    "\n",
    "# Merge survey, visited and site to a single data frame\n",
    "# of surveys with visit and site details\n",
    "\n",
    "test = pd.merge(left=survey, right=visited, left_on=\"taken\", right_on=\"ident\")\n",
    "\n",
    "m2m = pd.merge(left=test, right=site, left_on=\"site\", right_on=\"name\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Cleaning data for analysis.\n",
    "Changing data types of dirty data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using categorical data type.\n",
    "```python\n",
    "# Convert the sex column to type 'category'\n",
    "tips.sex = tips.sex.astype(\"category\")\n",
    "\n",
    "# Convert the smoker column to type 'category'\n",
    "tips.smoker = tips.smoker.astype(\"category\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using numeric data.\n",
    "```python\n",
    "# Convert 'total_bill' to a numeric dtype\n",
    "tips['total_bill'] = pd.to_numeric(tips['total_bill'], errors='coerce')\n",
    "\n",
    "# Convert 'tip' to a numeric dtype\n",
    "tips['tip'] = pd.to_numeric(tips[\"tip\"], errors=\"coerce\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regular expresions.\n",
    "```python\n",
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Compile the pattern: prog\n",
    "prog = re.compile('\\d{3}-\\d{3}-\\d{4}')\n",
    "\n",
    "# See if the pattern matches\n",
    "result = prog.match('123-456-7890')\n",
    "print(bool(result))\n",
    "\n",
    "# See if the pattern matches\n",
    "result2 = prog.match('1123-456-7890')\n",
    "print(bool(result2))\n",
    "\n",
    "# Find the numeric values: matches\n",
    "matches = re.findall('\\d+', 'the recipe calls for 10 strawberries and 1 banana')\n",
    "\n",
    "# Print the matches\n",
    "print(matches)\n",
    "\n",
    "# Write the first pattern\n",
    "pattern1 = bool(re.match(pattern='\\d{3}-\\d{3}-\\d{4}', string='123-456-7890'))\n",
    "print(pattern1)\n",
    "\n",
    "# Write the second pattern\n",
    "pattern2 = bool(re.match(pattern='\\$\\d*\\.\\d{2}', string='$123.45'))\n",
    "print(pattern2)\n",
    "\n",
    "# Write the third pattern\n",
    "pattern3 = bool(re.match(pattern='[A-Z]\\w*', string='Australia'))\n",
    "print(pattern3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using functions to clean data.\n",
    "```python\n",
    "# Define recode_gender()\n",
    "def recode_gender(gender):\n",
    "\n",
    "    # Return 0 if gender is 'Female'\n",
    "    if gender == \"Female\":\n",
    "        return 0\n",
    "    \n",
    "    # Return 1 if gender is 'Male'    \n",
    "    elif gender == \"Male\":\n",
    "        return 1\n",
    "    \n",
    "    # Return np.nan    \n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the sex column\n",
    "tips['recode'] = tips[\"sex\"].apply(recode_gender)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using lambda functions.\n",
    "```python\n",
    "# Write the lambda function using replace\n",
    "tips['total_dollar_replace'] = tips.total_dollar.apply(lambda x: x.replace('$', ''))\n",
    "\n",
    "# Write the lambda function using regular expressions\n",
    "tips['total_dollar_re'] = tips.total_dollar.apply(lambda x: re.findall('\\d+\\.\\d+', x)[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Drop the duplicates: tracks_no_duplicates\n",
    "tracks_no_duplicates = tracks.drop_duplicates()\n",
    "\n",
    "# Calculate the mean of the Ozone column: oz_mean\n",
    "oz_mean = airquality.Ozone.mean()\n",
    "\n",
    "# Replace all the missing values in the Ozone column with the mean\n",
    "airquality['Ozone'] = airquality.Ozone.fillna(oz_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assert statements.\n",
    "This will return an Assert error if false.\n",
    "```python\n",
    "# Assert that there are no missing values\n",
    "assert ebola.notnull().all().all()\n",
    "\n",
    "# Assert that all values are >= 0\n",
    "assert (ebola >= 0).all().all()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Case study.\n",
    "Do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def check_null_or_valid(row_data):\n",
    "    \"\"\"Function that takes a row of data,\n",
    "    drops all missing values,\n",
    "    and checks if all remaining values are greater than or equal to 0\n",
    "    \"\"\"\n",
    "    no_na = row_data.dropna()\n",
    "    numeric = pd.to_numeric(no_na)\n",
    "    ge0 = numeric >= 0\n",
    "    return ge0\n",
    "\n",
    "# Check whether the first column is 'Life expectancy'\n",
    "assert g1800s.columns[0] == \"Life expectancy\"\n",
    "\n",
    "# Check whether the values in the row are valid\n",
    "assert g1800s.iloc[:, 1:].apply(check_null_or_valid, axis=1).all().all()\n",
    "\n",
    "# Check that there is only one instance of each country\n",
    "assert g1800s['Life expectancy'].value_counts()[0] == 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Convert the year column to numeric\n",
    "gapminder.year = pd.to_numeric(gapminder.year)\n",
    "\n",
    "# Test if country is of type object\n",
    "assert gapminder.country.dtypes == np.object\n",
    "\n",
    "# Test if year is of type int64\n",
    "assert gapminder.year.dtypes == np.int64\n",
    "\n",
    "# Test if life_expectancy is of type float64\n",
    "assert gapminder.life_expectancy.dtypes == np.float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Print invalid_countries, a list of countries that doesn't \n",
    "# contain only letters, periods, and spaces\n",
    "\n",
    "\n",
    "countries = gapminder.country.drop_duplicates()\n",
    "\n",
    "pattern = '^[A-Za-z\\s\\.]*$'\n",
    "\n",
    "invalid_countries = countries[~countries.str.contains(pattern)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Assert that country does not contain any missing values\n",
    "assert pd.notnull(gapminder.country).all()\n",
    "\n",
    "# Assert that year does not contain any missing values\n",
    "assert pd.notnull(gapminder.year).all()\n",
    "\n",
    "# Drop the missing values\n",
    "gapminder = gapminder.dropna()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Add first subplot\n",
    "plt.subplot(2, 1, 1) \n",
    "\n",
    "# Create a histogram of life_expectancy\n",
    "gapminder.life_expectancy.plot(kind=\"hist\")\n",
    "\n",
    "# Group gapminder: gapminder_agg\n",
    "gapminder_agg = gapminder.groupby('year')['life_expectancy'].mean()\n",
    "\n",
    "# Print the head of gapminder_agg\n",
    "print(gapminder_agg.head())\n",
    "\n",
    "# Print the tail of gapminder_agg\n",
    "print(gapminder_agg.tail())\n",
    "\n",
    "# Add second subplot\n",
    "plt.subplot(2, 1, 2)\n",
    "\n",
    "# Create a line plot of life expectancy per year\n",
    "gapminder_agg.plot()\n",
    "\n",
    "# Add title and specify axis labels\n",
    "plt.title('Life expectancy over the years')\n",
    "plt.ylabel('Life expectancy')\n",
    "plt.xlabel('Year')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save both DataFrames to csv files\n",
    "gapminder.to_csv('gapminder.csv')\n",
    "gapminder_agg.to_csv('gapminder_agg.csv')\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datacamp Personal Takeaways \n",
    "## pandas Foundations by Dhavide Aruliah\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Data ingestion & inspection.\n",
    "Use pandas to review shape and current status of data.\n",
    "\n",
    "### No relevant new info!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Exploratory data analysis.\n",
    "Use pandas to quickly generate insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting on different rows.\n",
    "\n",
    "```python\n",
    "# This formats the plots such that they appear on separate rows\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# Plot the PDF\n",
    "df.fraction.plot(ax=axes[0], kind='hist', normed=True, bins=30, range=(0,.3))\n",
    "plt.show()\n",
    "\n",
    "# Plot the CDF\n",
    "df.fraction.plot(ax=axes[1], kind=\"hist\", normed=True, cumulative=True, bins=30, range=(0,.3))\n",
    "plt.show()\n",
    "\n",
    "# Display the box plots on 3 separate rows and 1 column\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1)\n",
    "\n",
    "# Generate a box plot of the fare prices for the First passenger class\n",
    "titanic.loc[titanic['pclass'] == 1].plot(ax=axes[0], y='fare', kind='box')\n",
    "\n",
    "# Generate a box plot of the fare prices for the Second passenger class\n",
    "titanic.loc[titanic[\"pclass\"] == 2].plot(ax=axes[1], y='fare', kind='box')\n",
    "\n",
    "# Generate a box plot of the fare prices for the Third passenger class\n",
    "titanic.loc[titanic[\"pclass\"] == 3].plot(ax=axes[2], y='fare', kind='box')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Time series in pandas.\n",
    "Use pandas format, slice and use time for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Prepare a format string: time_format\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "\n",
    "# Convert date_list into a datetime object: my_datetimes\n",
    "my_datetimes = pd.to_datetime(date_list, format=time_format)  \n",
    "\n",
    "# Construct a pandas Series using temperature_list and my_datetimes: time_series\n",
    "time_series = pd.Series(temperature_list, index=my_datetimes)\n",
    "\n",
    "# Extract the hour from 9pm to 10pm on '2010-10-11': ts1\n",
    "ts1 = ts0.loc['2010-10-11 21:00:00':'2010-10-11 22:00:00']\n",
    "\n",
    "# Extract '2010-07-04' from ts0: ts2\n",
    "ts2 = ts0.loc['2010-07-04']\n",
    "\n",
    "# Extract data from '2010-12-15' to '2010-12-31': ts3\n",
    "ts3 = ts0.loc['2010-12-15':'2010-12-31']\n",
    "\n",
    "# Reindex without fill method: ts3\n",
    "ts3 = ts2.reindex(ts1.index)\n",
    "\n",
    "# Reindex with fill method, using forward fill: ts4\n",
    "ts4 = ts2.reindex(ts1.index, method= \"ffill\")\n",
    "\n",
    "# Combine ts1 + ts2: sum12\n",
    "sum12 = ts1 + ts2\n",
    "\n",
    "# Combine ts1 + ts3: sum13\n",
    "sum13 = ts1 + ts3\n",
    "\n",
    "# Combine ts1 + ts4: sum14\n",
    "sum14 = ts1 + ts4\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling with pandas.\n",
    "\n",
    "```python\n",
    "# Downsample to 6 hour data and aggregate by mean: df1\n",
    "df1 = df.Temperature.resample('6H').mean()\n",
    "\n",
    "# Downsample to daily data and count the number of data points: df2\n",
    "df2 = df.Temperature.resample('D').count()\n",
    "\n",
    "# Extract temperature data for August: august\n",
    "august = df.loc[\"August 2010\", \"Temperature\"]\n",
    "\n",
    "# Downsample to obtain only the daily highest temperatures in August: august_highs\n",
    "august_highs = august.resample('D').max()\n",
    "\n",
    "# Extract temperature data for February: february\n",
    "february = df.loc[\"February 2010\", 'Temperature']\n",
    "\n",
    "# Downsample to obtain the daily lowest temperatures in February: february_lows\n",
    "february_lows = february.resample('D').min()\n",
    "\n",
    "# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\n",
    "unsmoothed = df['Temperature']['2010-Aug-01':'2010-Aug-15']\n",
    "\n",
    "# Apply a rolling mean with a 24 hour window: smoothed\n",
    "smoothed = unsmoothed.rolling(window=24).mean()\n",
    "\n",
    "# Create a new DataFrame with columns smoothed and unsmoothed: august\n",
    "august = pd.DataFrame({'smoothed':smoothed, 'unsmoothed':unsmoothed})\n",
    "\n",
    "# Plot both smoothed and unsmoothed data using august.plot().\n",
    "august.plot()\n",
    "plt.show()\n",
    "\n",
    "# Extract the August 2010 data: august\n",
    "august = df['Temperature']['August-2010']\n",
    "\n",
    "# Resample to daily data, aggregating by max: daily_highs\n",
    "daily_highs = august.resample('D').max()\n",
    "\n",
    "# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August\n",
    "daily_highs_smoothed = daily_highs.rolling(window=7).mean()\n",
    "print(daily_highs_smoothed)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series resampling frequencies:\n",
    "\n",
    "Input|Description\n",
    "---|---\n",
    "'min','T' | minute\n",
    "'H' | hour\n",
    "'D' | day\n",
    "'B' | business day\n",
    "'W' | week\n",
    "'M' | month\n",
    "'Q' | quarter\n",
    "'Y' | year\n",
    "'2W' | two week\n",
    "'3D' | three day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating time series.\n",
    "\n",
    "```python\n",
    "\n",
    "# Strip extra whitespace from the column names: df.columns\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Extract data for which the destination airport is Dallas: dallas\n",
    "dallas = df['Destination Airport'].str.contains('DAL')\n",
    "\n",
    "# Compute the total number of Dallas departures each day: daily_departures\n",
    "daily_departures = dallas.resample('D').sum()\n",
    "\n",
    "# Generate the summary statistics for daily Dallas departures: stats\n",
    "stats = daily_departures.describe()\n",
    "\n",
    "# Reset the index of ts2 to ts1, and then use linear interpolation to fill in the NaNs: ts2_interp\n",
    "ts2_interp = ts2.reindex(ts1.index).interpolate(how='linear')\n",
    "\n",
    "# Compute the absolute difference of ts1 and ts2_interp: differences \n",
    "differences = np.abs(ts1 - ts2_interp)\n",
    "\n",
    "# Generate and print summary statistics of the differences\n",
    "print(differences.describe())\n",
    "\n",
    "# Build a Boolean mask to filter for the 'LAX' departure flights: mask\n",
    "mask = df['Destination Airport'] == 'LAX'\n",
    "\n",
    "# Use the mask to subset the data: la\n",
    "la = df[mask]\n",
    "\n",
    "# Combine two columns of data to create a datetime series: times_tz_none \n",
    "times_tz_none = pd.to_datetime(la['Date (MM/DD/YYYY)'] + ' ' + la['Wheels-off Time'] )\n",
    "\n",
    "# Localize the time to US/Central: times_tz_central\n",
    "times_tz_central = times_tz_none.dt.tz_localize('US/Central')\n",
    "\n",
    "# Convert the datetimes from US/Central to US/Pacific\n",
    "times_tz_pacific = times_tz_central.dt.tz_convert('US/Pacific')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series plot.\n",
    "\n",
    "Passing a matlab style string:\n",
    "\n",
    "```python\n",
    "'k.-'\n",
    "\n",
    "```\n",
    "\n",
    "Color|Marker|Line\n",
    "---|---|---\n",
    "k: black| .: dot| -:solid\n",
    "b: blue|o: circle| : dotted\n",
    "g: green| \\*: star| _: dashed\n",
    "r: red | s: square| \n",
    "c: cyan| +: plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Case study - Sunlight in Austin.\n",
    "Use pandas to complete reading, cleaning, statistical and visual exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Cleaning\n",
    "```python\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the data file: df\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Print the output of df.head()\n",
    "print(df.head())\n",
    "\n",
    "# Read in the data file with header=None: df_headers\n",
    "df_headers = pd.read_csv(data_file, header=None)\n",
    "\n",
    "# Print the output of df_headers.head()\n",
    "print(df_headers.head())\n",
    "\n",
    "# Split on the comma to create a list: column_labels_list\n",
    "column_labels_list = column_labels.split(',')\n",
    "\n",
    "# Assign the new column labels to the DataFrame: df.columns\n",
    "df.columns = column_labels_list\n",
    "\n",
    "# Remove the appropriate columns: df_dropped\n",
    "df_dropped = df.drop(list_to_drop, axis='columns')\n",
    "\n",
    "# Print the output of df_dropped.head()\n",
    "print(df_dropped.head())\n",
    "\n",
    "# Convert the date column to string: df_dropped['date']\n",
    "df_dropped['date'] = df_dropped.date.astype(str)\n",
    "\n",
    "# Pad leading zeros to the Time column: df_dropped['Time']\n",
    "df_dropped['Time'] = df_dropped['Time'].apply(lambda x:'{:0>4}'.format(x))\n",
    "\n",
    "# Concatenate the new date and Time columns: date_string\n",
    "date_string = df_dropped.date + df_dropped.Time\n",
    "\n",
    "# Convert the date_string Series to datetime: date_times\n",
    "date_times = pd.to_datetime(date_string, format='%Y%m%d%H%M')\n",
    "\n",
    "# Set the index to be the new date_times container: df_clean\n",
    "df_clean = df_dropped.set_index(date_times)\n",
    "\n",
    "# Print the output of df_clean.head()\n",
    "print(df_clean.head())\n",
    "\n",
    "# Print the dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011\n",
    "print(df_clean.loc['2011-June-20 8:00:00':'2011-Jun-20 9:00:00', 'dry_bulb_faren'])\n",
    "\n",
    "# Convert the dry_bulb_faren column to numeric values: df_clean['dry_bulb_faren']\n",
    "df_clean['dry_bulb_faren'] = pd.to_numeric(df_clean['dry_bulb_faren'], errors=\"coerce\")\n",
    "\n",
    "# Print the transformed dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011\n",
    "print(df_clean.loc['2011-June-20 8:00:00':'2011-Jun-20 9:00:00', 'dry_bulb_faren'])\n",
    "\n",
    "# Convert the wind_speed and dew_point_faren columns to numeric values\n",
    "df_clean['wind_speed'] = pd.to_numeric(df_clean['wind_speed'], errors=\"coerce\")\n",
    "df_clean['dew_point_faren'] = pd.to_numeric(df_clean['dew_point_faren'], errors=\"coerce\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical exploratory data analysis\n",
    "\n",
    "```python\n",
    "# Print the median of the dry_bulb_faren column\n",
    "print(df_clean.dry_bulb_faren.median())\n",
    "\n",
    "# Print the median of the dry_bulb_faren column for the time range '2011-Apr':'2011-Jun'\n",
    "print(df_clean.loc['2011-Apr':'2011-Jun', 'dry_bulb_faren'].median())\n",
    "\n",
    "# Print the median of the dry_bulb_faren column for the month of January\n",
    "print(df_clean.loc['2011-Jan', 'dry_bulb_faren'].median())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Downsample df_clean by day and aggregate by mean: daily_mean_2011\n",
    "daily_mean_2011 = df_clean.resample('D').mean()\n",
    "\n",
    "# Extract the dry_bulb_faren column from daily_mean_2011 using .values: daily_temp_2011\n",
    "daily_temp_2011 = daily_mean_2011.dry_bulb_faren.values\n",
    "\n",
    "# Downsample df_climate by day and aggregate by mean: daily_climate\n",
    "daily_climate = df_climate.resample('D').mean()\n",
    "\n",
    "# Extract the Temperature column from daily_climate using .reset_index(): daily_temp_climate\n",
    "daily_temp_climate = daily_climate.reset_index()['Temperature']\n",
    "\n",
    "# Compute the difference between the two arrays and print the mean difference\n",
    "difference = daily_temp_2011 - daily_temp_climate\n",
    "print(difference.mean())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# From previous steps\n",
    "is_sky_clear = df_clean['sky_condition']=='CLR'\n",
    "sunny = df_clean.loc[is_sky_clear]\n",
    "sunny_daily_max = sunny.resample('D').max()\n",
    "is_sky_overcast = df_clean['sky_condition'].str.contains('OVC')\n",
    "overcast = df_clean.loc[is_sky_overcast]\n",
    "overcast_daily_max = overcast.resample('D').max()\n",
    "\n",
    "# Calculate the mean of sunny_daily_max\n",
    "sunny_daily_max_mean = sunny_daily_max.mean()\n",
    "\n",
    "# Calculate the mean of overcast_daily_max\n",
    "overcast_daily_max_mean = overcast_daily_max.mean()\n",
    "\n",
    "# Print the difference (sunny minus overcast)\n",
    "print(sunny_daily_max_mean - overcast_daily_max_mean)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the visibility and dry_bulb_faren columns and resample them: weekly_mean\n",
    "weekly_mean = df_clean[['visibility', 'dry_bulb_faren']].resample(\"W\").mean()\n",
    "\n",
    "# Print the output of weekly_mean.corr()\n",
    "print(weekly_mean.corr())\n",
    "\n",
    "# Plot weekly_mean with subplots=True\n",
    "weekly_mean.plot(subplots=True)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# From previous steps\n",
    "is_sky_clear = df_clean['sky_condition'] == 'CLR'\n",
    "resampled = is_sky_clear.resample('D')\n",
    "sunny_hours = resampled.sum()\n",
    "total_hours = resampled.count()\n",
    "sunny_fraction = sunny_hours / total_hours\n",
    "\n",
    "# Make a box plot of sunny_fraction\n",
    "sunny_fraction.plot(kind='box')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Resample dew_point_faren and dry_bulb_faren by Month, aggregating the maximum values: monthly_max\n",
    "monthly_max = df_clean[['dew_point_faren','dry_bulb_faren']].resample(\"M\").max()\n",
    "\n",
    "# Generate a histogram with bins=8, alpha=0.5, subplots=True\n",
    "monthly_max.plot(kind=\"hist\", bins=8, alpha=0.5, subplots=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final stretch\n",
    "\n",
    "```python\n",
    "\n",
    "# Extract the maximum temperature in August 2010 from df_climate: august_max\n",
    "august_max = df_climate.Temperature.loc['2010-August'].max()\n",
    "print(august_max)\n",
    "\n",
    "# Resample August 2011 temps in df_clean by day & aggregate the max value: august_2011\n",
    "august_2011 = df_clean.dry_bulb_faren.loc['2011-August'].resample(\"D\").max()\n",
    "\n",
    "# Filter for days in august_2011 where the value exceeds august_max: august_2011_high\n",
    "august_2011_high = august_2011[august_2011 > august_max]\n",
    "\n",
    "# Construct a CDF of august_2011_high\n",
    "august_2011_high.plot(kind='hist', normed=True, cumulative=True, bins=25)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
